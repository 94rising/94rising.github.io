---
title: "Sprint 2025-BY26-9 회고"
author: "이순범"
description: "AI 에이전트 성능 개선 - Assistant Agent 개발, 월간 분석 자동화, 비즈니스 메트릭 대시보드 구축"
image:
  url: "../../assets/images/3.jpg"
  alt: "Among the Stars - Generated by AI"
pubDate: 2025-11-26
tags: ["tech","sprint", "n8n", "Azure-OpenAI", "Datadog", "LLM-Prompt-Engineering", "Map-Reduce"]
---

## 개요

11월 스프린트에서는 DevOps 팀의 운영 효율성을 높이기 위한 AI 자동화 시스템을 구축했다. 핵심은 세 가지였다. 첫째, 운영 티켓의 품질을 실시간으로 분석하고 가이드를 제공하는 Assistant Agent. 둘째, 월간 운영 데이터를 종합 분석하여 리포트를 자동 생성하는 워크플로우. 셋째, 비즈니스 메트릭을 인프라 모니터링과 통합하는 Datadog 대시보드.

이 글에서는 시스템 설계 과정에서 경험한 기술적 선택들과 그 과정에서 얻은 인사이트를 공유한다.


## 무엇을 만들었나

### 실시간 티켓 품질 분석 (Assistant Agent)

DevOps 팀으로 들어오는 요청 티켓은 종류가 다양하다. K8S 서비스 생성, 리소스 생성 요청, 권한 신청 등. 문제는 각 요청마다 필요한 정보가 다르고, 정보가 부족한 상태로 티켓이 들어오면 담당자가 추가 질문을 해야 한다는 점이었다.

Assistant Agent는 15분 주기로 새로운 티켓을 스캔하고, AI가 정보 완성도를 평가한다. 부족한 정보가 있으면 자동으로 코멘트를 남겨 요청자에게 안내한다. 담당자가 티켓을 확인할 때는 이미 필요한 정보가 갖춰진 상태가 되는 것이 목표다.

### 월간 운영 분석 자동화

매월 400-500건의 운영 티켓이 처리된다. 이 데이터에는 팀의 업무 패턴, 반복되는 요청(Toil), 문서화가 필요한 영역 등 귀중한 인사이트가 숨어있다. 하지만 수작업으로 분석하기엔 시간이 부족했다.

월간 분석 워크플로우는 전월 티켓을 자동으로 수집하고, LLM이 카테고리별 분포, 반복 패턴, 장애 트렌드 등을 분석한다. 결과는 Confluence 페이지로 자동 발행되고, Slack으로 팀에 알림이 간다.

```
Schedule Trigger (매월 1일)
  → Jira: 전월 티켓 조회
  → Code: 전처리 & 메트릭 계산
  → LLM: Map-Reduce 방식 분석
  → Confluence: 리포트 자동 생성
  → Slack: 팀 알림
```

### 비즈니스 메트릭 대시보드

기존 모니터링은 CPU, Memory 같은 인프라 메트릭에 집중되어 있었다. 이번에 애플리케이션 로그에서 비즈니스 트랜잭션(주문, 결제 등)을 추출하여 Datadog 대시보드에 통합했다. 인프라 상태와 비즈니스 지표를 같은 화면에서 상관관계 분석할 수 있게 되었다.


## 기술 딥다이브

### 1. 이벤트 기반 vs 폴링 기반 - 자동화 아키텍처의 선택

실시간 티켓 분석을 설계할 때 두 가지 선택지가 있었다. Webhook을 사용한 이벤트 기반 방식과 Schedule Trigger를 사용한 폴링 방식이었다.

환경 제약으로 폴링 방식을 선택했는데, 이 과정에서 두 아키텍처의 트레이드오프를 이해하게 되었다.

| 방식 | 장점 | 단점 |
|-----|-----|-----|
| 이벤트 기반 | 즉시 반응, 리소스 효율적 | 이벤트 유실 가능, 외부 시스템 의존 |
| 폴링 기반 | 신뢰성 높음, 실패 시 재처리 용이 | 지연 존재, 상태 관리 필요 |

폴링 방식에서 중복 처리를 방지하기 위해 `AI_ANALYZED` 레이블을 사용했다. 분석이 완료되면 레이블이 붙고, 다음 주기에는 이 레이블이 없는 티켓만 조회한다. 분석이 실패하면 레이블이 붙지 않으므로 자동으로 재시도된다.

이 "상태 마커 기반 폴링" 패턴은 다른 자동화에도 적용 가능하다. 배포 자동화에서 "DEPLOY_READY" 태그가 붙은 커밋만 처리하거나, 문서 자동화에서 특정 라벨이 붙은 페이지만 검토하는 식이다.

**배운 점**: 이벤트 기반이 항상 우월한 것은 아니다. 시스템의 신뢰성 요구사항과 실패 복구 전략을 고려하면 폴링 방식이 더 적합한 경우도 많다.


### 2. LLM 프롬프트 설계 - 범용성과 정확도의 균형

초기 프롬프트는 RDS 요청에 대한 상세한 예시를 포함하고 있었다. 의도는 "이렇게 상세하게 분석해줘"라는 가이드였지만, 실제로는 다른 카테고리에서도 RDS 관련 정보를 요청하는 편향이 발생했다.

프롬프트 길이는 400줄에 달했고, LLM은 중간 규칙을 무시하는 경향을 보였다.

해결책은 "덜어내기"였다. 예시 출력을 제거하고, 카테고리별 필수 정보를 표 형태로 구조화했다.

| 카테고리 | 필수 정보 |
|---------|----------|
| K8S 서비스 | 클라우드, 환경, 서비스명, repo, pod spec... |
| RDS | 클라우드, 환경, DB종류, 버전... |
| DevOps Tools | 도구별 상이 |

핵심 규칙은 "해당 카테고리의 필수 정보만 체크하라"는 한 문장이었다. 프롬프트 길이는 절반 이하로 줄었고, 정확도는 오히려 향상되었다.

**배운 점**: 범용 시스템에서는 상세한 예시보다 명확한 구조가 더 효과적이다. 프롬프트를 코드처럼 생각하면, "Don't Repeat Yourself" 원칙이 여기서도 적용된다.


### 3. Map-Reduce 패턴 - 대용량 데이터의 LLM 처리

월간 분석에서 400-500건의 티켓을 한 번에 처리해야 했다. GPT-4o-mini의 Context Window는 128K 토큰이지만, 모든 티켓의 상세 내용을 포함하면 초과할 가능성이 있었다.

고전적인 Map-Reduce 패턴을 LLM 워크플로우에 적용했다.

**Map 단계**: 50개 단위 배치로 나누어 GPT-4o-mini가 분류와 정보 추출을 수행한다. 각 배치의 출력은 구조화된 JSON이다.

**Reduce 단계**: 모든 배치 결과를 병합하고, GPT-4o가 종합 분석과 인사이트를 도출한다.

핵심은 **듀얼 모델 전략**이다. Map 단계는 "분류"라는 단순한 작업이므로 저렴한 GPT-4o-mini를 사용한다. Reduce 단계는 "인사이트 도출"이라는 고차원 추론이 필요하므로 GPT-4o를 사용한다. 이 전략으로 전체 비용을 약 1/10로 줄이면서 분석 품질을 유지할 수 있었다.

**배운 점**: LLM의 Context Window 제한은 단점이 아니라 설계 제약이다. 이 제약을 수용하고 분산 처리 패턴을 적용하면, 오히려 비용 최적화와 처리 안정성이라는 부가 이점을 얻을 수 있다.


### 4. 모니터링의 확장 - 인프라에서 비즈니스까지

DevOps 팀의 모니터링은 전통적으로 인프라 메트릭에 집중되어 있었다. 하지만 "매출이 떨어졌다"는 상황에서는 인프라 대시보드만으로 원인을 파악하기 어렵다.

이번에 시도한 것은 "비즈니스 로그를 인프라 모니터링 파이프라인에 통합"하는 것이었다. 애플리케이션에서 특정 마커가 포함된 로그를 남기면, Datadog 파이프라인에서 이를 필터링하고 구조화된 메트릭으로 변환한다.

이 접근 방식은 다른 서비스에도 적용 가능하다. 로그에 표준화된 마커를 남기는 규칙만 정하면, 파이프라인 설정을 복제하여 여러 서비스의 비즈니스 메트릭을 통합할 수 있다.

**배운 점**: 모니터링은 "서버가 살아있는가"를 넘어 "비즈니스가 잘 작동하는가"까지 확장되어야 한다. 인프라 팀과 비즈니스 팀의 데이터를 같은 플랫폼에서 볼 수 있게 만드는 것이 DevOps의 가치 확장 방향 중 하나다.


## 회고

이번 스프린트에서 가장 큰 학습은 **제약을 설계 기회로 전환하는 사고방식**이었다.

LLM의 Context Window 제한은 Map-Reduce 패턴 적용의 계기가 되었고, 이를 통해 비용 최적화라는 부가 이점을 얻었다. Webhook을 사용할 수 없는 환경 제약은 레이블 기반 상태 관리 패턴을 만들어냈고, 이는 오히려 실패 복구와 운영 유연성 측면에서 이점이 되었다.

실시간 분석(15분 주기)과 월간 종합 분석이라는 두 가지 시간 축의 워크플로우가 만들어졌다. 실시간 분석은 개별 티켓의 품질을 즉시 개선하고, 월간 분석은 팀 전체의 업무 패턴과 개선 기회를 파악한다. 두 워크플로우가 동일한 카테고리 체계를 공유하므로, 인사이트의 일관성이 유지된다.

다음 단계는 실제 운영 데이터를 수집하여 시스템의 효과를 정량적으로 측정하는 것이다. 월간 분석 리포트의 Toil 식별 결과를 바탕으로 자동화 우선순위를 결정하고, 지속적으로 개선해 나갈 계획이다.