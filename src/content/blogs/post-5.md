---
title: "Sprint 2025-BY26-10 회고"
author: "이순범"
description: "프로덕션 배포와 운영의 균형 - AI 자동화와 일상 운영 업무 사이에서"
image:
  url: "../../assets/images/5.png"
  alt: "운영 자동화 시스템의 프로덕션 환경 구성도"
pubDate: 2025-12-09
tags: ["tech", "sprint", "DevOps", "Automation"]
---

## 개요

2주간의 스프린트를 한 문장으로 요약하면: **"새로운 자동화 시스템을 프로덕션에 안착시키면서, 동시에 일상적인 DevOps 업무를 계속 수행하기"**였다.

지난 스프린트에서 개발한 AI 티켓 분석 시스템을 실제 운영 환경에 배포했다. 개발 환경에서는 잘 작동하던 시스템이 프로덕션에서는 예상치 못한 문제들을 드러냈다. 동시에 Azure 인프라 리소스 생성, DevOps 도구 권한 관리, QA 환경 구축 등 일상적인 운영 업무도 병행해야 했다.


## 무엇을 했나

### AI 분석 시스템 프로덕션 배포

지난 스프린트에서 만든 티켓 품질 분석 시스템을 실제 운영에 투입했다. 15분마다 새 티켓을 스캔하고, 정보가 부족하면 자동으로 코멘트를 남긴다. 

개발 환경에서는 특정 티켓 하나로 테스트했지만, 프로덕션에서는 모든 미분석 티켓을 처리해야 했다. 중복 분석을 방지하기 위해 `AI_ANALYZED` 레이블을 붙이고, 품질 점수에 따라 `HIGH_QUALITY`와 `NEEDS_INFO` 레이블을 추가하도록 구성했다.

가장 중요했던 건 **기존 사용자 레이블을 보존**하는 것이었다. 사용자가 수동으로 추가한 레이블이 사라지면 큰 혼란이 생긴다. API가 배열로만 동작하고 업데이트 시 기존 값이 초기화된다는 제약을 고려해 concat 방식으로 구현했다.

### 월간 분석 워크플로우 본격 가동

월 400-500건의 티켓을 자동 분석하여 리포트를 생성하는 시스템을 실제로 돌렸다. 지난 스프린트에서 설계한 Map-Reduce 구조가 실전에서 어떻게 작동하는지 확인하는 단계였다.

큰 문제 없이 첫 리포트가 생성되었고, 반복 작업 패턴과 문서화 우선순위가 자동으로 식별되었다. 다음 달부터는 이 리포트를 팀 회고 때 활용할 예정이다.

### 일상적인 DevOps 운영

자동화 시스템 배포만 한 건 아니었다. 실제 업무의 상당 부분은 다음과 같은 것들이었다:

- **Azure 인프라 리소스 생성**: QA 환경 서비스 구축, NLB 고정 IP 할당, DNS 설정
- **DevOps Tools 권한 관리**: Jira, GitLab, ArgoCD, Datadog 등 다양한 도구 접근 권한 요청 처리
- **트러블 슈팅**: 개발팀의 Git 이슈, 배포 문제 등 지원

이런 반복적인 운영 업무를 처리하면서, 동시에 자동화 시스템을 개선하는 것이 실제 DevOps의 모습이다.


## 프로덕션의 현실

### "작동한다"와 "운영 가능하다"는 다르다

개발 환경에서 시스템이 잘 작동하는 것과 프로덕션에서 안정적으로 운영되는 것은 완전히 다른 문제다. 이번에 그 차이를 체감했다.

개발 환경에서는 특정 티켓 하나로 테스트했다. API 응답은 항상 예상한 구조였고, 네트워크는 안정적이었다. 하지만 프로덕션에서는 달랐다. 

- API 응답이 때로는 `issueData.key`에, 때로는 `issueData.fields.key`에 값이 있었다
- 배열에서 데이터를 가져올 때 인덱스 에러가 발생했다
- 15분 폴링 중 일시적인 네트워크 불안정으로 요청이 실패했다

해결책은 **방어적 코딩**이었다. Optional chaining(`?.`), `.first()` 메서드, try-catch 블록. 화려하지는 않지만, 이런 것들이 시스템을 안정적으로 만들었다.

### 레이블 하나에 담긴 사용자 경험

`AI_ANALYZED` 레이블을 추가하는 건 간단한 작업처럼 보였다. 하지만 사용자가 수동으로 추가한 레이블을 보존하지 않으면 큰 문제가 생긴다는 걸 뒤늦게 깨달았다.

팀원들은 티켓에 `urgent`, `backend`, `security` 같은 레이블을 달아 분류한다. 만약 AI가 레이블을 업데이트하면서 기존 레이블을 지워버린다면? 사용자는 자신의 분류 체계가 사라진 것을 보고 시스템을 신뢰하지 않게 될 것이다.

결국 배열 concat 방식으로 구현했다. 기술적으로는 단순하지만, "사용자가 만든 것을 존중한다"는 원칙이 담긴 선택이었다.

### 자동화와 운영 업무의 균형

이번 스프린트에서 가장 어려웠던 건 시간 배분이었다. AI 시스템 개선에만 집중하고 싶었지만, 현실은 달랐다.

매일 들어오는 권한 요청, 인프라 리소스 생성, 트러블 슈팅. 이런 "중단 업무(Interrupt-driven work)"가 계획한 작업을 자꾸 밀어냈다. 오전에 세운 계획이 오후가 되면 완전히 달라지는 날도 많았다.

흥미로운 점은, 이런 반복적인 운영 업무를 처리하면서 AI 시스템의 정확도가 개선되었다는 것이다. DevOps Tools 권한 요청을 여러 건 처리하다 보니 반복 패턴이 보였고, 이를 AI 프롬프트에 반영했다. 

운영 업무는 방해가 아니라 **시스템 개선의 데이터 소스**였던 셈이다.


## 배운 것들

### 점진적 배포가 답이다

처음부터 모든 티켓을 대상으로 배포하지 않았다. 특정 티켓 하나로 테스트 → 제한된 범위로 파일럿 → 전체 배포 순서로 진행했다. 

각 단계에서 문제가 발견되었고, 다음 단계로 넘어가기 전에 수정했다. 만약 처음부터 전체 배포했다면 수백 개의 티켓에 잘못된 코멘트가 달렸을 것이다.

완벽한 시스템은 없다. 하지만 실패의 영향 범위를 제어할 수는 있다.

### 정량화의 중요성

AI 시스템을 배포했지만, 실제로 얼마나 효과가 있는지 측정하지 못했다. "티켓 품질이 좋아진 것 같다"는 느낌은 있지만, 구체적인 수치가 없다.

- 티켓 보완율은? (AI 코멘트 후 정보가 추가된 비율)
- 담당자 시간 절감은? (추가 질문 횟수 감소)
- 카테고리 정확도는? (AI 분류와 실제 처리 카테고리 일치율)

### 문서화는 코드만큼 중요하다

월간 분석 리포트가 자동으로 생성되면서, 운영 데이터가 "휘발성 지식"에서 "축적된 인사이트"로 바뀌고 있다. 

이전에는 "지난달에 RDS 요청이 많았던 것 같은데..."라는 애매한 기억에 의존했다면, 이제는 리포트를 열어 정확한 수치를 확인할 수 있다. 이 데이터는 팀 회고, 업무 우선순위 결정, 자동화 계획 수립에 활용될 것이다.

**암묵지를 명시지로 바꾸는 것**, 그것이 자동화의 또 다른 가치다.

화려한 신기술보다는, 작동하는 시스템을 만들고 측정하고 개선하는 것. 그것이 DevOps의 본질이 아닐까.